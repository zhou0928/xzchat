
import fs from "node:fs";
import path from "node:path";
import fetch from "node-fetch";
import { chunkText, calculateCosineSimilarity } from "./utils.js";
import { getFileList } from "./tools.js";
import { embeddingCache } from "./utils/cache.js";
import { logger } from "./utils/logger.js";

const INDEX_FILE = ".newapi-chat-index.json";

// Simple embedding fetcher with fallback
async function fetchEmbedding(text, config) {
    if (!config.apiKey) throw new Error("API Key required for embeddings");
    
    let baseUrl = config.baseUrl || "https://api.openai.com/v1";
    if (baseUrl.endsWith("/")) baseUrl = baseUrl.slice(0, -1);
    
    // Adjust for /v1
    let url = baseUrl;
    // Remove /chat/completions if present
    if (url.endsWith("/chat/completions")) url = url.replace("/chat/completions", "");
    // Ensure /v1
    if (!url.endsWith("/v1")) url += "/v1";
    // Append /embeddings
    url += "/embeddings";

    // Handle duplicate v1
    if (url.includes("/v1/v1")) url = url.replace("/v1/v1", "/v1");

    const modelsToTry = config.embeddingModel 
        ? [config.embeddingModel] 
        : ["text-embedding-3-small", "text-embedding-ada-002"];

    let lastError = null;

    for (const model of modelsToTry) {
        try {
            const response = await fetch(url, {
                method: "POST",
                headers: {
                    "Content-Type": "application/json",
                    "Authorization": `Bearer ${config.apiKey}`
                },
                body: JSON.stringify({
                    input: text,
                    model: model
                })
            });

            if (!response.ok) {
                const err = await response.text();
                // If it's a model error (404 or specific 500s), try next model
                if (response.status === 404 || response.status >= 500 || err.includes("model_not_found")) {
                    logger.warn(`Embedding model '${model}' failed, trying next...`);
                    lastError = new Error(`Embedding API Error (${response.status}): ${err}`);
                    continue; 
                }
                throw new Error(`Embedding API Error (${response.status}): ${err}`);
            }

            const data = await response.json();
            if (!data.data || !data.data[0] || !data.data[0].embedding) {
                throw new Error("Invalid embedding response format");
            }
            return data.data[0].embedding;

        } catch (e) {
            lastError = e;
            // If network error, maybe retry? For now just continue to next model if applicable
            if (modelsToTry.length > 1 && model !== modelsToTry[modelsToTry.length - 1]) {
                continue;
            }
        }
    }
    
    throw lastError;
}

/**
 * è·å–æ–‡æœ¬çš„åµŒå…¥å‘é‡ï¼ˆå¸¦ç¼“å­˜ï¼‰
 */
async function getCachedEmbedding(text, config) {
    const cacheKey = `embed:${text.substring(0, 100)}:${text.length}`;
    
    // æ£€æŸ¥ç¼“å­˜
    const cached = embeddingCache.get(cacheKey);
    if (cached) {
        logger.debug('ä½¿ç”¨ç¼“å­˜çš„åµŒå…¥å‘é‡');
        return cached;
    }
    
    // è·å–æ–°çš„åµŒå…¥å‘é‡
    const embedding = await fetchEmbedding(text, config);
    embeddingCache.set(cacheKey, embedding);
    
    return embedding;
}

/**
 * æ‰¹é‡è·å–åµŒå…¥å‘é‡ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
 */
async function batchFetchEmbeddings(texts, config, options = {}) {
    const {
        concurrency = 5,
        delay = 100,
        retryCount = 2,
        retryDelay = 2000
    } = options;
    
    const results = new Array(texts.length).fill(null);
    const errors = [];
    let completed = 0;
    
    // ä½¿ç”¨å¹¶å‘æ§åˆ¶å™¨
    async function processBatch(startIndex) {
        for (let i = startIndex; i < texts.length; i += concurrency) {
            const text = texts[i];
            let lastError = null;
            
            for (let retry = 0; retry <= retryCount; retry++) {
                try {
                    const embedding = await getCachedEmbedding(text, config);
                    results[i] = embedding;
                    completed++;
                    
                    if (completed % 10 === 0) {
                        process.stdout.write(`[${completed}/${texts.length}]`);
                    }
                    
                    break;
                } catch (e) {
                    lastError = e;
                    
                    // å¦‚æœæ˜¯429é”™è¯¯ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´
                    if (e.message.includes("429")) {
                        logger.warn(`é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… ${retryDelay}ms åé‡è¯•...`);
                        await new Promise(r => setTimeout(r, retryDelay));
                    } else if (retry < retryCount) {
                        await new Promise(r => setTimeout(r, delay));
                    }
                }
            }
            
            if (results[i] === null && lastError) {
                errors.push({ index: i, error: lastError.message });
                logger.error(`åµŒå…¥è·å–å¤±è´¥ [${i}]`, { error: lastError.message });
            }
            
            // æ·»åŠ å»¶è¿Ÿé¿å…é€Ÿç‡é™åˆ¶
            await new Promise(r => setTimeout(r, delay));
        }
    }
    
    // å¹¶å‘å¤„ç†
    const workers = [];
    for (let i = 0; i < concurrency; i++) {
        workers.push(processBatch(i));
    }
    
    await Promise.all(workers);
    
    return { results, errors };
}

/**
 * ä¸ºå•ä¸ªæ–‡ä»¶åˆ›å»ºåµŒå…¥å‘é‡
 */
async function processFile(filePath, dir, config) {
    const fullPath = path.join(dir, filePath);
    
    if (!fs.existsSync(fullPath)) return [];
    
    // è·³è¿‡å¤§æ–‡ä»¶æˆ–äºŒè¿›åˆ¶æ–‡ä»¶
    const stats = fs.statSync(fullPath);
    if (stats.size > 100 * 1024) return []; // Skip > 100KB
    
    const ext = path.extname(filePath).toLowerCase();
    if ([".png", ".jpg", ".jpeg", ".gif", ".lock", ".bin", ".mp3", ".wav"].includes(ext)) return [];
    
    try {
        const content = fs.readFileSync(fullPath, "utf-8");
        const chunks = chunkText(content, 500); // 500 tokens ~ 2000 chars
        
        // æ‰¹é‡è·å–åµŒå…¥å‘é‡
        const { results: embeddings, errors } = await batchFetchEmbeddings(
            chunks.filter(c => c.trim()),
            config,
            { concurrency: 3, delay: 100 }
        );
        
        const validChunks = [];
        let embedIndex = 0;
        
        for (let i = 0; i < chunks.length; i++) {
            const chunk = chunks[i];
            if (!chunk.trim()) continue;
            
            const embedding = embeddings[embedIndex];
            if (embedding) {
                validChunks.push({
                    file: filePath,
                    chunkIndex: i,
                    content: chunk,
                    embedding
                });
            }
            embedIndex++;
        }
        
        if (errors.length > 0) {
            logger.warn(`æ–‡ä»¶ ${filePath} éƒ¨åˆ†å—åµŒå…¥å¤±è´¥`, { failedChunks: errors.length });
        }
        
        return validChunks;
    } catch (e) {
        logger.error(`å¤„ç†æ–‡ä»¶å¤±è´¥: ${filePath}`, { error: e.message });
        return [];
    }
}

export async function indexCodebase(dir, config, options = {}) {
    const {
        concurrency = 3,
        showProgress = true
    } = options;
    
    const files = getFileList(dir);
    const validFiles = files.filter(f => f !== INDEX_FILE);
    
    logger.info(`å¼€å§‹ç´¢å¼•ï¼Œæ‰¾åˆ° ${validFiles.length} ä¸ªæ–‡ä»¶`, { concurrency });
    
    if (showProgress) {
        process.stdout.write(`ğŸ“š æ‰¾åˆ° ${validFiles.length} ä¸ªæ–‡ä»¶ã€‚å¼€å§‹å¹¶è¡Œç´¢å¼•...\n`);
    }
    
    let allChunks = [];
    let processed = 0;
    const errors = [];
    
    // å¹¶å‘å¤„ç†æ–‡ä»¶
    async function processFilesBatch(startIndex) {
        for (let i = startIndex; i < validFiles.length; i += concurrency) {
            const file = validFiles[i];
            try {
                const chunks = await processFile(file, dir, config);
                allChunks.push(...chunks);
                processed++;
                
                if (showProgress && processed % 5 === 0) {
                    process.stdout.write(".");
                }
            } catch (e) {
                errors.push({ file, error: e.message });
                logger.error(`æ–‡ä»¶å¤„ç†å¤±è´¥: ${file}`, { error: e.message });
            }
        }
    }
    
    // å¯åŠ¨å¹¶å‘å·¥ä½œçº¿ç¨‹
    const workers = [];
    for (let i = 0; i < concurrency; i++) {
        workers.push(processFilesBatch(i));
    }
    
    await Promise.all(workers);
    
    if (showProgress) {
        process.stdout.write(`\nğŸ’¾ ä¿å­˜ç´¢å¼•...\n`);
    }
    
    // ä¿å­˜ç´¢å¼•
    fs.writeFileSync(
        path.join(dir, INDEX_FILE), 
        JSON.stringify(allChunks, null, 2)
    );
    
    logger.info('ç´¢å¼•å®Œæˆ', { totalChunks: allChunks.length, processedFiles: processed, errors: errors.length });
    
    if (showProgress) {
        process.stdout.write(`âœ… ç´¢å¼•å®Œæˆï¼ä» ${processed} ä¸ªæ–‡ä»¶ä¸­åˆ›å»ºäº† ${allChunks.length} ä¸ªå—ã€‚\n`);

        if (errors.length > 0) {
            process.stdout.write(`âš ï¸  ${errors.length} ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥\n`);
        }
    }
    
    return allChunks.length;
}

export async function loadIndex(dir) {
    const indexPath = path.join(dir, INDEX_FILE);
    if (!fs.existsSync(indexPath)) return null;
    try {
        const index = JSON.parse(fs.readFileSync(indexPath, "utf-8"));
        logger.info('åŠ è½½ç´¢å¼•', { indexPath, chunks: index.length });
        return index;
    } catch (e) {
        logger.error('åŠ è½½ç´¢å¼•å¤±è´¥', { error: e.message });
        return null;
    }
}

export async function searchCodebase(query, dir, config, options = {}) {
    const {
        topK = 5,
        useCache = true
    } = options;
    
    const index = await loadIndex(dir);
    if (!index) {
        throw new Error("Index not found. Please run indexing first.");
    }
    
    logger.info('æœç´¢ä»£ç åº“', { query, indexSize: index.length, topK });
    
    // ä½¿ç”¨ç¼“å­˜çš„æŸ¥è¯¢åµŒå…¥
    const queryEmbedding = useCache 
        ? await getCachedEmbedding(query, config)
        : await fetchEmbedding(query, config);
    
    // å¹¶è¡Œè®¡ç®—ç›¸ä¼¼åº¦ï¼ˆå¯¹äºå¤§ç´¢å¼•ï¼‰
    const scored = await Promise.all(
        index.map(async (item) => ({
            ...item,
            score: calculateCosineSimilarity(queryEmbedding, item.embedding)
        }))
    );
    
    // æ’åºå¹¶è¿”å›å‰ topK
    scored.sort((a, b) => b.score - a.score);
    const results = scored.slice(0, topK);
    
    logger.info('æœç´¢å®Œæˆ', { resultsCount: results.length });
    
    return results;
}

/**
 * æ¸…é™¤ RAG ç›¸å…³ç¼“å­˜
 */
export async function clearRAGCache() {
    const { embeddingCache } = await import('./utils/cache.js');
    embeddingCache.clear();
    logger.info('RAG ç¼“å­˜å·²æ¸…ç©º');
}

/**
 * è·å– RAG ç»Ÿè®¡ä¿¡æ¯
 */
export async function getRAGStats() {
    const { embeddingCache, ragIndexCache } = await import('./utils/cache.js');
    return {
        embedding: embeddingCache.getStats(),
        index: ragIndexCache.getStats()
    };
}
